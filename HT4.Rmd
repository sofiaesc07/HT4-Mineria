---
title: "HT4 - Arboles de desición"
author: "Stefan Quintana, Sofía Escobar, Wilfredo Gallegos"
date: "3/7/2023"
output: html_document
---

```{r, echo=FALSE}
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(ggplot2)
library(tidyr)

datos <- read.csv("train.csv")

datos <- datos %>% mutate_at(c('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities'
                               , 'LotConfig', 'LandSlope', 'Condition2', 'RoofMatl', 'Exterior2nd', 'Electrical'), as.factor)

porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training1<-datos[corte,]
test1<-datos[-corte,]


```

```{r, echo = FALSE}
datos2 <- dplyr::select_if(datos, is.numeric)
datos2 <- na.omit(datos2)
datosc <- scale(datos2)
cor(datosc)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]
```


##Pregunta 1. Particion de los datos en dos conjuntos

Como los datos están balanceados se hizo una partición aleatoria utilizando el 70% de los datos para entrenamiento y el 30% de los datos para prueba.  
```{r}
porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datosc),nrow(datosc)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]

```

###Conjunto de entrenamiento (cantidad de muestras: r nrow(train)):  
```{r echo=FALSE}
head(training)
```

###Conjunto de Prueba (cantidad de muestras: `r nrow(test)`):  
```{r}
head(test)
```

##Pregunta 2. Arbol de regresión con todas las variables
```{r}
arbol1 <- rpart(SalePrice ~ ., data=training)
rpart.plot(arbol1)
```
Para el árbol de regresión se puede observar que los resultados indican la probabilidad de que una casa tenga cierta característica según otras características que poseen. Al observar los resultados de las pruebas se puede ver que el entrenamiento de los datos fue exitoso ya que se obtuvo un valor cercano a 0 y ambos resultados son diferentes, lo cual nos indica que no hubo overfitting.

##Pregunta 3. Preddición del resultado
```{r}
pred1 <- predict(arbol1, data = training1)
p1 <- sum((mean(training1$SalePrice)-training1$SalePrice) ^ 2)
p2 <- sum((training1$SalePrice-pred1) ^ 2)
p3 <- 1-(p2 / p1)
p3

```

Predijo el resultado con un error del 2% lo cuál no es malo pero puede mejorar, y lo hizo con una longitud de 4 por lo que debería de intentar con mayor longitud para ver si la prección mejora y cambia. Basandonos en el R^2 observamos que es bastante aceptable ya que es es bastante cercano a 1 por lo que se deduce que es un modelo de predicción bastante bueno.

##Pregunta 4. Arbol de regresión con todas las variables
```{r}
modelo1 <- rpart(SalePrice ~ ., data=training, maxdepth=2)
modelo2 <- rpart(SalePrice ~ ., data=training, maxdepth=3)
modelo3 <- rpart(SalePrice ~ ., data=training, maxdepth=4)
rpart.plot(modelo1)
rpart.plot(modelo2)
rpart.plot(modelo3)

```

##Pregunta 5. Compare resultados
Observamos como el arbol con longitud 6 es de 4 por lo que se indica que es la longitud maxima y por lo tanto la máxima predicción y minimo error es del 2%, esta de igual forma es mejor que la de longitud 2 con 5% y la de longitud 3 que aunque sea en menor porcentaje 2% en las otras predicciones de igual forma tiene mayores porcentajes que la de longitud 6.


## Pregunta 6. Economica, intermedia o cara
```{r}
training1$clasification <- ifelse(training1$SalePrice > 214000, "Caras", ifelse(training1$SalePrice>163000, "Intemedia", "Economicas"))
table(training1$clasification)
```
Los limites de como clasificar fueron basados en el analisis exploratorio de los datos de la hoja pasada en donde tomas el 1er y 3er cuartil y la media de la variable SalePrice. 


## Pregunta 7. Elabore un árbol de clasificación utilizando la variable respuesta que creó en el punto
anterior. Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde
que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las
casas, no incluya el precio de venta para entrenar el modelo.

```{r}
training1<-training1[,-81]
modclasificacion<-rpart(clasification~.,data = training1,method = "class")
rpart.plot(modclasificacion)
```

## Pregunta 8.Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar


```{r}
y <- ifelse(test1$SalePrice > 214000, "Caras", ifelse(test1$SalePrice>163000, "Intemedia", "Economicas"))
test1 <- test1[,-81]
y <- as.factor(y)

pred2<-predict(modclasificacion, newdata = test1[,-81])
pred2 <- apply(pred2, 1, function(x) colnames(pred2)[which.max(x)])
pred2 <- factor(pred2)
```

Podemos observar en las siguientes tablas que el error que se tuvo en la predicción de casas catalogadas como caras fue de un excedente de 2, para la predicción de casas economicas fue de un exceso 11 y para las casas intermedias fue de una falta de 13 casas. Presentado como porcentajes de error, Se tuvo 1.81% de error en las casas caras, un error de 5.14% para las economicas y un error de 11.30% para las casas de clasificación intermedia. De igual manera se puede observar la similaridad en los gráficos siguientes.

### Tabla valores reales de clasificación
```{r}
table(y)
```

### Tabla valores predecidos de clasificación 
```{r}
table(pred2)
plot(pred2, col="green",density=20,angle=135+geom_text(aes(label = signif(pred2)), nudge_y = 0))
plot(y , col="blue",density=20,angle=135)

```

## PRoblema 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol
de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde
se equivocó menos y la importancia que tienen los errores.

```{r}
confusionMatrix(y, pred2)
```


## Pregunta 10 Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior?

```{r, echo = FALSE}
set.seed(123)
datos2$SalePrice <- as.factor(datos2$SalePrice)

ent <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

tune_grid = expand.grid(cp=c(0.001))

vtree <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree
```

## Pregunta 11, realizar diferentes arboles.
### Profundidad 4
```{r, echo = FALSE}
#Profundidad 4
vtree1 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 4, minbucket = 4)

vtree1
```


### Profundidad 5
```{r, echo = FALSE}
#Profundidad 5
vtree2 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree2
```


### Profundidad 6
```{r, echo = FALSE}
#Profundidad 6
vtree3 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 6, minbucket = 6)

vtree3
```
Comparando los tres modelos podemos notar que el más preciso es el que tiene profundidad 5, validando lo antes propuesto.


## Pregunta 12 Repita los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos.
```{r, echo = FALSE}
clasificadorRF <- randomForest(SalePrice ~ ., data = datos2, ntree = 250)
y_pred <- predict(clasificadorRF, newdata = test)
y_pred
```
Se puede notar que random forest encontró el mejor modelo en cuánto a la precisión,



