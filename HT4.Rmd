---
title: "HT4 - Arboles de desición"
author: "Stefan Quintana, Sofía Escobar, Wilfredo Gallegos"
date: "3/7/2023"
output: html_document
---

```{r, echo=FALSE}
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)
library(ggplot2)
library(tidyr)

datos <- read.csv("train.csv")

datos <- datos %>% mutate_at(c('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities'
                               , 'LotConfig', 'LandSlope', 'Condition2', 'RoofMatl', 'Exterior2nd', 'Electrical'), as.factor)

porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training1<-datos[corte,]
test1<-datos[-corte,]


```

```{r, echo = FALSE}
datos2 <- dplyr::select_if(datos, is.numeric)
datos2 <- na.omit(datos2)
datosc <- scale(datos2)
cor(datosc)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]
```


##Pregunta 1. Particion de los datos en dos conjuntos

Como los datos están balanceados se hizo una partición aleatoria utilizando el 70% de los datos para entrenamiento y el 30% de los datos para prueba.  
```{r}
porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datosc),nrow(datosc)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]

```

###Conjunto de entrenamiento (cantidad de muestras: r nrow(train)):  
```{r echo=FALSE}
head(training)
```

###Conjunto de Prueba (cantidad de muestras: `r nrow(test)`):  
```{r}
head(test)
```

##Pregunta 2. Arbol de regresión con todas las variables
```{r}
arbol1 <- rpart(SalePrice ~ ., data=training)
rpart.plot(arbol1)
```

##Pregunta 3. Preddición del resultado
```{r}
pred1 <- predict(arbol1, data = training1)
p1 <- sum((training1$SalePrice - mean(training1$SalePrice)) ^ 2)
p2 <- sum((pred1 - training1$SalePrice) ^ 2)
p3 <- (p2 / p1)-1
p3

```

Predijo el resultado con un error del 2% lo cuál no es malo pero puede mejorar, y lo hizo con una longitud de 4 por lo que debería de intentar con mayor longitud para ver si la prección mejora y cambia. Basandonos en el R^2 observamos que es bastante aceptable ya que es es bastante cercano a 1 por lo que se deduce que es un modelo de predicción bastante bueno.

##Pregunta 4. Arbol de regresión con todas las variables
```{r}
modelo1 <- rpart(SalePrice ~ ., data=training, maxdepth=2)
modelo2 <- rpart(SalePrice ~ ., data=training, maxdepth=3)
modelo3 <- rpart(SalePrice ~ ., data=training, maxdepth=4)
rpart.plot(modelo1)
rpart.plot(modelo2)
rpart.plot(modelo3)

```

##Pregunta 5. Compare resultados
Observamos como el arbol con longitud 6 es de 4 por lo que se indica que es la longitud maxima y por lo tanto la máxima predicción y minimo error es del 2%, esta de igual forma es mejor que la de longitud 2 con 5% y la de longitud 3 que aunque sea en menor porcentaje 2% en las otras predicciones de igual forma tiene mayores porcentajes que la de longitud 6.


## Pregunta 6. Economica, intermedia o cara
```{r}
training1$clasification <- ifelse(training1$SalePrice > 214000, "Caras", ifelse(training1$SalePrice>163000, "Intemedia", "Economicas"))
table(training1$clasification)
```
Los limites de como clasificar fueron basados en el analisis exploratorio de los datos de la hoja pasada en donde tomas el 1er y 3er cuartil y la media de la variable SalePrice. 


## Pregunta 7. Elabore un árbol de clasificación utilizando la variable respuesta que creó en el punto
anterior. Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde
que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las
casas, no incluya el precio de venta para entrenar el modelo.

```{r}
training1<-training1[,-81]
modclasificacion<-rpart(clasification~.,data = training1,method = "class")
rpart.plot(modclasificacion)
```

## Pregunta 8.Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar


```{r}
y <- ifelse(test1$SalePrice > 214000, "Caras", ifelse(test1$SalePrice>163000, "Intemedia", "Economicas"))
test1 <- test1[,-81]
y <- as.factor(y)

pred2<-predict(modclasificacion, newdata = test1[,-81])
pred2 <- apply(pred2, 1, function(x) colnames(pred2)[which.max(x)])
pred2 <- factor(pred2)
```

Podemos observar en las siguientes tablas que el error que se tuvo en la predicción de casas catalogadas como caras fue de un excedente de 2, para la predicción de casas economicas fue de un exceso 11 y para las casas intermedias fue de una falta de 13 casas. Presentado como porcentajes de error, Se tuvo 1.81% de error en las casas caras, un error de 5.14% para las economicas y un error de 11.30% para las casas de clasificación intermedia. De igual manera se puede observar la similaridad en los gráficos siguientes.

### Tabla valores reales de clasificación
```{r}
table(y)
```

### Tabla valores predecidos de clasificación 
```{r}
table(pred2)
```

Grafico de datos de predicción

```{r}
plot(pred2, col="green",density=20,angle=135+geom_text(aes(label = signif(pred2)), nudge_y = 0))
```

Gráfico de valores reales

```{r}
plot(y , col="blue",density=20,angle=135)

```

## PRoblema 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde se equivocó menos y la importancia que tienen los errores.

A partir de los datos obtenidos con la matriz de confusión tenemos una precision de 80.41% en los datos, de los cuales la tabla nos indica que se equivocó en 33 predicciones para la clasificacion de casas intermedias, se equivocó en 28 predicciones para la clasificación de casas económicas y se equivocó en 25 predicciones para la clasificación de casas caras. Podemos notar que el algoritmo se equivocó más en la prediccion de clasificación intermedia, y se equivocó menos en la clasificación de casas caras. 


```{r}
confusionMatrix(y, pred2)
```


## Pregunta 10 Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior?

```{r, echo = FALSE}
set.seed(123)
datos2$SalePrice <- as.factor(datos2$SalePrice)

ent <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

tune_grid = expand.grid(cp=c(0.001))

vtree <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree
```

## Pregunta 11, realizar diferentes arboles.
### Profundidad 4
```{r, echo = FALSE}
#Profundidad 4
vtree1 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 4, minbucket = 4)

vtree1
```


### Profundidad 5
```{r, echo = FALSE}
#Profundidad 5
vtree2 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree2
```


### Profundidad 6
```{r, echo = FALSE}
#Profundidad 6
vtree3 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 6, minbucket = 6)

vtree3
```
Comparando los tres modelos podemos notar que el más preciso es el que tiene profundidad 5, validando lo antes propuesto.


## Pregunta 12 Repita los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos.
```{r, echo = FALSE}
clasificadorRF <- randomForest(SalePrice ~ ., data = datos2, ntree = 250)
y_pred <- predict(clasificadorRF, newdata = test)
y_pred
```
Se puede notar que random forest encontró el mejor modelo en cuánto a la precisión,



