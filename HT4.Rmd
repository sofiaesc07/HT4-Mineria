---
title: "HT4 - Arboles de desición"
author: "Stefan Quintana, Sofía Escobar, Wilfredo Gallegos"
date: "3/7/2023"
output: html_document
---

```{r, echo=FALSE}
library(dplyr)
library(rpart)
library(rpart.plot)
library(caret)
library(tree)
library(randomForest)


datos <- read.csv("train.csv")

datos <- datos %>% mutate_at(c('MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities'
                               , 'LotConfig', 'LandSlope', 'Condition2', 'RoofMatl', 'Exterior2nd', 'Electrical'), as.factor)

porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training1<-datos[corte,]
test1<-datos[-corte,]


```

```{r, echo = FALSE}
datos2 <- dplyr::select_if(datos, is.numeric)
datos2 <- na.omit(datos2)
datosc <- scale(datos2)
cor(datosc)
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]
```


##Pregunta 1. Particion de los datos en dos conjuntos

Como los datos están balanceados se hizo una partición aleatoria utilizando el 70% de los datos para entrenamiento y el 30% de los datos para prueba.  
```{r}
porcentaje<-0.7
set.seed(123)
corte <- sample(nrow(datosc),nrow(datosc)*porcentaje)
training<-datos[corte,]
test<-datos[-corte,]

```

###Conjunto de entrenamiento (cantidad de muestras: r nrow(train)):  
```{r echo=FALSE}
head(training)
```

###Conjunto de Prueba (cantidad de muestras: `r nrow(test)`):  
```{r}
head(test)
```

##Pregunta 2. Arbol de regresión con todas las variables
```{r}
arbol1 <- rpart(SalePrice ~ ., data=training)
rpart.plot(arbol1)
```

##Pregunta 3. Preddición del resultado
```{r}
pred1 <- predict(arbol1, data = training1)
p1 <- sum((training1$SalePrice - mean(training1$SalePrice)) ^ 2)
p2 <- sum((pred1 - training1$SalePrice) ^ 2)
p3 <- (p2 / p1)-1
p3

```

Predijo el resultado con un error del 2% lo cuál no es malo pero puede mejorar, y lo hizo con una longitud de 4 por lo que debería de intentar con mayor longitud para ver si la prección mejora y cambia. Basandonos en el R^2 observamos que es bastante aceptable ya que es es bastante cercano a 1 por lo que se deduce que es un modelo de predicción bastante bueno.

##Pregunta 4. Arbol de regresión con todas las variables
```{r}
modelo1 <- rpart(SalePrice ~ ., data=training, maxdepth=2)
modelo2 <- rpart(SalePrice ~ ., data=training, maxdepth=3)
modelo3 <- rpart(SalePrice ~ ., data=training, maxdepth=4)
rpart.plot(modelo1)
rpart.plot(modelo2)
rpart.plot(modelo3)

```

##Pregunta 5. Compare resultados
Observamos como el arbol con longitud 6 es de 4 por lo que se indica que es la longitud maxima y por lo tanto la máxima predicción y minimo error es del 2%, esta de igual forma es mejor que la de longitud 2 con 5% y la de longitud 3 que aunque sea en menor porcentaje 2% en las otras predicciones de igual forma tiene mayores porcentajes que la de longitud 6.


## Pregunta 6. Economica, intermedia o cara
```{r}
training1$clasification <- ifelse(training1$SalePrice > 214000, "Caras", ifelse(training1$SalePrice>163000, "Intemedia", "Economicas"))
table(training1$clasification)
```
Los limites de como clasificar fueron basados en el analisis exploratorio de los datos de la hoja pasada en donde tomas el 1er y 3er cuartil y la media de la variable SalePrice. 


## Pregunta 7. Elabore un árbol de clasificación utilizando la variable respuesta que creó en el punto
anterior. Explique los resultados a los que llega. Muestre el modelo gráficamente. Recuerde
que la nueva variable respuesta es categórica, pero se generó a partir de los precios de las
casas, no incluya el precio de venta para entrenar el modelo.

```{r}
training1<-training1[,-81]
modclasificacion<-rpart(clasification~.,data = training1,method = "class")
#rpart.plot(modclasificacion)
```

## Pregunta 8.Utilice el modelo con el conjunto de prueba y determine la eficiencia del algoritmo para clasificar


```{r}
y <- ifelse(test1$SalePrice > 214000, "Caras", ifelse(test1$SalePrice>163000, "Intemedia", "Economicas"))
test1 <- test1[,-81]
y <- as.factor(y)

pred2<-predict(modclasificacion, newdata = test1[,-81])
pred2 <- apply(pred2, 1, function(x) colnames(pred2)[which.max(x)])
pred2 <- factor(pred2)

confusionMatrix(y, pred2)

length(test1$clasification)
```

## PRoblema 9. Haga un análisis de la eficiencia del algoritmo usando una matriz de confusión para el árbol
de clasificación. Tenga en cuenta la efectividad, donde el algoritmo se equivocó más, donde
se equivocó menos y la importancia que tienen los errores.

```{r}
nrow(training)
nrow(test)
confusionMatrix(pred2, y)
```



```{r}
#y<-test
#test$clasification <- ifelse(test$SalePrice > 214000, "Caras", ifelse(test$SalePrice>163000, "Intemedia", "Economicas"))

y <- test[,"clasification"]
test<-test%>%select(-c("SalePrice","clasification"))
training<-training %>% select(-c("SalePrice"))
#training$clasification <- ifelse(training$SalePrice > 214000, "Caras", ifelse(training$SalePrice>163000, "Intemedia", "Economicas"))

#modclasificaciontest<-rpart(test$clasification~.,data = test,method = "class")



pred2<-predict(modclasificacion,data = test)
pred2 <- apply(pred2, 1, function(x) colnames(pred2)[which.max(x)])
pred2 <- factor(pred2)
confusionMatrix(pred2, y)
#testnew <- test                                # Duplicate test data set
#testnew$Utilities[which(!(testnew$Utilities %in% unique(training$Utilities)))] <- NA  # Replace new levels by NA 
#pred2<-predict(clasificacion,newdata = testnew)
```



```{r}


test$clasification <- ifelse(test$SalePrice > 214000, "Caras", ifelse(test$SalePrice>163000, "Intemedia", "Economicas"))
  
clasificacion<-rpart(training$clasification~.,data = training,method = "class")

y <- factor(test$clasification)
rpart.plot(clasificacion)

pred2<-predict(clasificacion,data = test)
pred2 <- apply(pred2, 1, function(x) colnames(pred2)[which.max(x)])
pred2 <- factor(pred2)
confusionMatrix(pred2, y)

table(train$Survived)
table(y)

```
## Pregunta 10 Entrene un modelo usando validación cruzada, prediga con él. ¿le fue mejor que al modelo anterior?

```{r, echo = FALSE}
set.seed(123)
datos2$SalePrice <- as.factor(datos2$SalePrice)

ent <- trainControl(method = "repeatedcv", number = 10, repeats = 2)

tune_grid = expand.grid(cp=c(0.001))

vtree <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree
```

## Pregunta 11, realizar diferentes arboles.
### Profundidad 4
```{r, echo = FALSE}
#Profundidad 4
vtree1 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 4, minbucket = 4)

vtree1
```


### Profundidad 5
```{r, echo = FALSE}
#Profundidad 5
vtree2 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 5, minbucket = 5)

vtree2
```


### Profundidad 6
```{r, echo = FALSE}
#Profundidad 6
vtree3 <- train(SalePrice ~ ., data = datos2, method = "rpart", trControl = ent, tuneGrid = tune_grid, maxdepth = 6, minbucket = 6)

vtree3
```


## Pregunta 12 Repita los análisis usando random forest como algoritmo de predicción, explique sus resultados comparando ambos algoritmos.
```{r, echo = FALSE}
clasificadorRF <- randomForest(SalePrice ~ ., data = datos2, ntree = 250)
y_pred <- predict(clasificadorRF, newdata = test)
y_pred
```




